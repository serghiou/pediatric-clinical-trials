---
title: 'Pediatric clinical trials: Regression'
author: "Stylianos Serghiou"
date: '`r format(Sys.time(), "%d/%m/%Y")`'
output:
  prettydoc::html_pretty:
    # no code_folding available
    theme: hpstr      # or: architect; https://github.com/yixuan/prettydoc
    highlight: github # or: vignette
    toc: TRUE         # no toc_float available
    df_print: kable   # obviates %>% kable; does not replace styling though
  tufte::tufte_handout: default
  pdf_document:
    highlight: tango
    df_print: kable
    latex_engine: pdflatex
    keep_tex: yes
  rmdformats::readthedown:
    highlight: kate
    df_print: kable    # obviates %>% kable; does not replace styling though
    code_folding: hide # or: show; (comment out to not give option)
  tufte::tufte_html: 
    toc: TRUE
  epuRate::epurate:
    df_print: kable
    toc: yes
  html_document:
    highlight: tango
    theme: sandstone
    df_print: kable
    toc: yes
    toc_depth: 2
    toc_float: yes
    css: "path_to_custom.css"
header-includes:
- \DeclareUnicodeCharacter{3B8}{~}
- \DeclareUnicodeCharacter{3B1}{~}
- \DeclareUnicodeCharacter{3B2}{~}
- \DeclareUnicodeCharacter{223C}{~}
- \DeclareUnicodeCharacter{2264}{~}
- \DeclareUnicodeCharacter{2265}{~}
- \DeclareUnicodeCharacter{2581}{~}
- \DeclareUnicodeCharacter{2582}{~}
- \DeclareUnicodeCharacter{2583}{~}
- \DeclareUnicodeCharacter{2585}{~}
- \DeclareUnicodeCharacter{2586}{~}
- \DeclareUnicodeCharacter{2587}{~} 
- \DeclareUnicodeCharacter{FB00}{~} 
- \usepackage{graphicx}
editor_options: 
  chunk_output_type: inline
---

<style>
p {

text-align: justify;
text-justify: interword;
padding: 0 0 0.5em 0

}
</style>

```{r setup, include=FALSE}
# Load packages
library(knitr)
library(rmdformats)
library(kableExtra)
library(ggplot2)
library(magrittr)



######### knitr

# Define chunk options
opts_chunk$set(
  echo = T,
  cache = F,  # if TRUE, no need to rerun chunks
  # cache.lazy = TRUE,  # use with big objects (>1 GB)
  cache.comments = F,  # do not rebuild if comments change
  tidy = F,  # can play with this
  warning = F, 
  message = F,
  comment = NA,
  fig.align = "center",
  fig.width = 7,
  # fig.path = "Figs/",  # export all figures to dir Figs
  linewidth = 91,
  width = 75
)


# Initiatialize hook
hook_output = knit_hooks$get("output")


# Hook to wrap output text when it exceeds 'n' using linewidth
knit_hooks$set(output = function(x, options) {
  
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    
    # wrap lines wider than 'n' 
    if (any(nchar(x) > n)) 
      x <- strwrap(x, width = n)
      x <- paste(x, collapse = "\n")
  }
  hook_output(x, options)
})


# Times a chunk and prints the time it took to run it under the chunk
# To time a chunk, include in the chunk options: {r my_chunk, timeit=TRUE}
knitr::knit_hooks$set(timeit = local({
  now = NULL
  function(before, options) {
    if (before) {
      now <<- Sys.time()
    } else {
      res = difftime(Sys.time(), now)
      now <<- NULL
      # use options$label if you want the chunk label as well
      paste('Time for this code chunk:', as.character(res))
    }
  }})
)


# For more knitr options visit: https://yihui.name/knitr/options/
# and his github page: https://github.com/yihui/knitr-examples



######### kableExtra

options(knitr.kable.NA = ''  # replace NAs in tables with blank
        , digits = 5)          # round digits (doesn't work without this here!)

## Example use
# data.frame(x = c(1,2,3), y = c(4,5,6), z = c(7,8,9)) %>% 
#   kable(booktabs = T) %>% kable_styling()

# Function to simplify table styling
sable <- function(tab, escape = T, full_width = F, drop = F, font_size = 12) {
  if (drop) {
    tab %>%
      kable(escape = escape, booktabs = T) %>%
      collapse_rows(valign = "top") %>% 
      kable_styling("striped", 
                    position = "center", 
                    full_width = full_width, 
                    font_size = font_size)
  } else {
    tab %>%
      kable(escape = escape, booktabs = T) %>%
      kable_styling("striped", 
                    position = "center", 
                    full_width = full_width,
                    font_size = font_size)
  }
}

## Guidelines
# No longer need to define options(knitr.table.format = "html"). It is now automatically done as soon as you load kableExtra
# No need to run kable() every time - done automatically as soon as you load kableExtra
# Loading kableExtra nullifies any styling applied by df_table: kable in the preamble - if you are content with standard formatting, DO NOT load kableExtra



#########  ggplot2

# Set up preferred theme in ggplot2
my_theme <- 
  # this and theme_minimal() are my favorite
  theme_light() +  
  theme(
    axis.ticks = element_blank(),
    axis.title = element_text(face = "bold"),
    axis.title.x = element_text(margin = margin(t = 20)),
    axis.title.y  = element_text(margin = margin(r = 10)),
    legend.key = element_rect(colour = NA, fill = NA),  # Avoid borders
    panel.border = element_blank(), 
    text = element_text(color = "grey20"),
    title = element_text(face = "bold")
  )

# Make the above theme the default theme
original_theme <- theme_set(my_theme)

# Use ggsave to save plots after plotting - this reduces size dramatically



######### Live preview

# Preview the HTML without having to re-knit
# https://www.r-bloggers.com/create-r-markdown-reports-and-presentations-even-better-with-these-3-practical-tips/amp/

# xaringan::infinite_moon_reader()




######### Tabbed sections

# You can organize content using tabs by applying the .tabset class attribute to headers within a document. This will cause all sub-headers of the header with the .tabset attribute to appear within tabs rather than as standalone sections. For example:

## Quarterly Results {.tabset}

### By Product



######### Update package

# To update the package use:
# Replace ~/serghiouTemplates/inst/rmarkdown/templates/report/skeleton.rmd
# library(devtools); setwd("/Users/Stelios/"); install("serghiouTemplates")
```


# Setup {.tabset}

<!-- Chunk called setup_2 to avoid running it automatically -->

```{r setup_2}
# Load packages
library(broom)
library(ggrepel)
library(magrittr)
library(sandwich)
library(tidyverse)
library(treemapify)


# Import data
trials <- read_csv(
  "../../data/tidy_data/trials-ihme.csv"
)

ihme <- read_csv(
  "../../data/tidy_data/ihme.csv", 
  col_types = cols(ihme_id = col_character(), who_id = col_character())
)

who <- read_csv(
  "../../data/tidy_data/who.csv", 
  col_types = cols(ID = col_character())
)
```


***


# Create dataset


```{r}
# Create an appropriate IHME
ihme_dev <- 
  list(
    `More developed` = ihme,
    `Less developed` = ihme,
    `All` = ihme
  ) %>% 
  bind_rows(.id = "dev")

# Create duplicated dataset
regression <-
  trials %>% 
  mutate(dev = if_else(is_developed, "More developed", "Less developed")) %>% 
  bind_rows(trials, .id = "id_dev") %>%
  mutate(dev = if_else(id_dev == 2, "All", dev)) %>% 
  filter(is_eligible, is_classified) %>%
  separate_rows(ihme_level_three, sep = "; ") %>%
  select(-condition) %>%
  right_join(ihme_dev, by = c("ihme_level_three" = "ihme_id", "dev")) %>%
  filter(level == "level_three") %>% 
  mutate(level_three = condition) %>% 
  left_join(select(who, ID, level_two), by = c("who_id" = "ID")) %>% 
  mutate(n_sample_adjust = n_sample / n_level_three)


# Summarize values
regression %<>%
  group_by(dev, level_three, dalys) %>% 
  summarise(
    sample_size = sum(n_sample_adjust, na.rm = T),
    n_studies = sum(!is.na(n_sample)),
    n_complete_enroll = sum(str_detect(status_june23_sc, "C|E|R"), na.rm = T),
    p_complete_enroll = mean(str_detect(status_june23_sc, "C|E|R"), na.rm = T)
  ) %>% 
  mutate(complete_enroll = case_when(
    is.na(p_complete_enroll) | is.nan(p_complete_enroll)  ~ NA_character_,
    p_complete_enroll > 0.5 ~ ">50%",
    p_complete_enroll < 0.25 ~ "0-25%",
    T ~ "25-50%"
  )) %>%
  mutate(complete_enroll = factor(complete_enroll)) %>%
  mutate(complete_enroll = fct_relevel(complete_enroll, ">50%", "25-50%")) %>%
  ungroup()

# Glimpse
glimpse(regression)
```


***


# Tables

## Sample per development

```{r}
regression %>%
  filter(dev != "All") %>% 
  group_by(dev) %>% 
  summarise(total_sample = sum(sample_size)) %>%
  mutate(p = scales::percent(total_sample / sum(total_sample), 0.1)) %>% 
  sable()
```


# Plots

## Boxplot

Boxplot of sample size.

```{r}
regression %>% 
  ggplot(aes(x = dev, y = sample_size, fill = dev, col = dev)) +
  geom_boxplot(alpha = 0.75, show.legend = F) +
  labs(x = NULL, y = "Total sample size") +
  scale_y_continuous(labels = scales::comma)

# Save
ggsave("../../output/figure_output/regression_boxplot_sample-size.jpg")
```

## 2D Histogram

Across all.

```{r}
regression %>% 
  ggplot(aes(x = dalys, y = sample_size)) +
  geom_hex() +
  labs(x = "DALYs", y = "Total sample size") +
  scale_x_continuous(labels = scales::unit_format(unit = "M", scale = 1e-6)) +
  scale_y_continuous(labels = scales::comma) +
  scale_fill_continuous(name = "Count\n")

# Save
ggsave(
  "../../output/figure_output/regression_2d-histogram.jpg",
  width = 8,
  height = 6
)
```


Stratified by development.

```{r}
regression %>% 
  ggplot(aes(x = dalys, y = sample_size, fill = dev)) +
  geom_hex() +
  labs(x = "DALYs", y = "Total sample size") +
  scale_x_continuous(labels = scales::unit_format(unit = "M", scale = 1e-6)) +
  scale_y_continuous(labels = scales::comma)

# Save
ggsave(
  "../../output/figure_output/regression_2d-histogram_stratified.jpg",
  width = 8,
  height = 6
)
```


## Original

```{r}
regression %>%
  ggplot(aes(x = dalys, y = sample_size)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x) +
  geom_text_repel(aes(label = level_three), size = 2, segment.size = 0.2) +
  facet_wrap(~ dev, nrow = 2) +
  labs(x = "DALYs (millions)", y = "Total sample size") +
  scale_x_continuous(labels = scales::unit_format(unit = "M", scale = 1e-6)) +
  scale_y_continuous(labels = scales::comma)

# Save
ggsave(
  "../../output/figure_output/regression_original.jpg",
  width = 13,
  height = 8
)
```


## Original - NB tests

```{r}
regression %>%
  filter(dev == "All") %>% 
  ggplot(aes(x = dalys, y = sample_size)) +
  geom_point() +
  geom_smooth(
    method = "lm", 
    aes(color = "LM"), 
    formula = y ~ x, 
    se = F
  ) +
  geom_smooth(
    method = "lm", 
    aes(color = "LM-log"), 
    formula = y ~ log(x), 
    se = F
  ) +
  geom_smooth(
    method = "glm",
    method.args = list(family = poisson), 
    aes(color = "Poisson"), 
    se = T
  ) +
  geom_smooth(
    method = MASS::glm.nb, 
    aes(color = "NB"), 
    se = F
  ) +
  facet_wrap(~ dev, nrow = 2) +
  labs(x = "DALYs (millions)", y = "Total sample size") +
  scale_x_continuous(labels = scales::unit_format(unit = "M", scale = 1e-6)) +
  scale_y_continuous(labels = scales::comma)

# Save
ggsave(
  "../../output/figure_output/regression_original_nb.jpg",
  width = 13,
  height = 8
)
```


## Original - Enrollment

```{r}
regression %>%
  ggplot(aes(x = dalys, y = sample_size)) +
  geom_point(aes(color = complete_enroll)) +
  geom_smooth(method = "lm", formula = y ~ x) +
  geom_text_repel(
    aes(label = level_three, color = complete_enroll), 
    size = 2, 
    segment.size = 0.2
  ) +
  facet_wrap(~ dev, nrow = 2) +
  labs(color = "Complete or recruiting") +
  scale_x_continuous(
    name = "DALYs (millions)",
    labels = scales::unit_format(unit = "M", scale = 1e-6)
  ) +
  scale_y_continuous(
    labels = scales::comma,
    name = "Total sample size"
  )

# Save
ggsave(
  "../../output/figure_output/regression_original_enrollment.jpg",
  width = 13,
  height = 8
)
```


## Log

```{r}
regression %>%
  ggplot(aes(x = dalys, y = sample_size)) +
  geom_point(color = scales::hue_pal()(1)) +
  geom_smooth(method = "lm", formula = y ~ x) +
  geom_text_repel(aes(label = level_three), size = 2, segment.size = 0.2) +
  facet_wrap(~ dev, nrow = 2) +
  labs(x = "Log-transformed DALYs (millions)", y = "Total sample size") +
  scale_x_continuous(
    trans = "log10",
    labels = scales::unit_format(unit = "M", scale = 1e-6)
  ) +
  scale_y_continuous(
    # trans = "log",
    labels = scales::comma
  )

# Save
ggsave(
  "../../output/figure_output/regression_log.jpg",
  width = 13,
  height = 8
)
```


## Log - Enrollment

```{r}
regression %>%
  ggplot(aes(x = dalys, y = sample_size)) +
  geom_point(aes(color = complete_enroll)) +
  geom_smooth(method = "lm", formula = y ~ x) +
  geom_text_repel(
    aes(label = level_three, color = complete_enroll), 
    size = 2, 
    segment.size = 0.2
  ) +
  facet_wrap(~ dev, nrow = 2) +
  labs(color = "Complete or recruiting") +
  scale_x_continuous(
    trans = "log10",
    name = "Log-transformed DALYs (millions)",
    labels = scales::unit_format(unit = "M", scale = 1e-6)
  ) +
  scale_y_continuous(
    labels = scales::comma,
    name = "Total sample size"
  )

# Save
ggsave(
  "../../output/figure_output/regression_log_enrollment.jpg",
  width = 13,
  height = 8
)
```


## Log - Poisson

```{r}
regression %>%
  ggplot(aes(x = dalys, y = sample_size)) +
  geom_text_repel(
    aes(label = level_three), 
    size = 3, 
    segment.color = "grey70",
    segment.size = 0.15,
    force = 70,
    max.iter = 1000000
  ) +
  geom_point(color = scales::hue_pal()(1)) +
  geom_smooth(
    method = "glm",
    method.args = list(family = quasipoisson),
    formula = y ~ x,
    se = T
  ) +
  facet_wrap(~ dev, nrow = 2) +
  labs(x = "Log-transformed DALYs (millions)", y = "Total sample size") +
  scale_x_continuous(
    trans = "log10",
    labels = scales::unit_format(unit = "M", scale = 1e-6)
  ) +
  scale_y_continuous(
    # trans = "log",
    labels = scales::comma
  ) +
  coord_cartesian(ylim = c(-150000, 200000))

# Save
ggsave(
  "../../output/figure_output/regression_log_poisson_chosen.jpg",
  width = 13,
  height = 8
)
```


## Log - Poisson - Enrollment

```{r}
regression %>%
  ggplot(aes(x = dalys, y = sample_size)) +
  geom_text_repel(
    aes(label = level_three), 
    size = 3,
    segment.color = "grey80",
    segment.size = 0.1,
    force = 50,
    max.time = 5,
    max.iter = 1000000
  ) +
  geom_point(aes(color = complete_enroll)) +
  geom_smooth(
    method = "glm",
    method.args = list(family = quasipoisson),
    formula = y ~ x,
    se = T
  ) +
  facet_wrap(~ dev, nrow = 2) +
  scale_x_continuous(
    trans = "log10",
    labels = scales::unit_format(unit = "M", scale = 1e-6),
    name = "Log-transformed DALYs (millions)"
  ) +
  scale_y_continuous(
    # trans = "log",
    labels = scales::comma,
    name = "Total sample size"
  ) +
  scale_color_discrete(
    name = "Complete or recruiting", 
    labels = c(">50%", "25-50%", "0-25%", "No studies")
  ) +
  coord_cartesian(ylim = c(-100000, 200000))

# Save
ggsave(
  "../../output/figure_output/regression_log_poisson_enrollment_chosen.jpg",
  width = 13,
  height = 8
)
```


***


# Regression analysis

Fit line.

```{r}
glm.fit1 <- 
  regression %>% 
  filter(dev != "All") %>% 
  mutate(dalys = dalys / 10^6) %>% 
  glm(sample_size ~ dalys + dev + dalys * dev, ., family = "quasipoisson")
```


Diagnostic plots.

```{r}
plot(glm.fit1)
```


Diagnostic statistics.

```{r}
broom::glance(glm.fit1) %>% sable()
```


Summarize regression results.

```{r}
broom::tidy(glm.fit1, conf.int = T, exp = T) %>% sable()
```

Obtain robust results using the sandwich estimator.

```{r}
# Calculate
pvals <- lmtest::coeftest(glm.fit1, vcov = sandwich)
confints <- lmtest::coefci(glm.fit1, vcov = sandwich)

# Construct final table
pvals %>% 
  cbind(confints) %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "Variable") %>% 
  as_tibble() %>% 
  mutate(across(c(Estimate, `2.5 %`, `97.5 %`), exp)) %>% 
  sable()
```

This table suggests that for every a million DALYs, the expected sample size increases by a median of 1.01 (95% CI, 1.008-1.02; P-value = 0.00002). It also suggests that in the observed trials, the sample size of studies from more developed countries was a median of 51% smaller than that of less developed countries, across levels of DALYs. However, this analysis does not suggest that this is generally true (95% CI, 0.17-1.44). No meaningful effect modification between DALYs and development was observed (95% CI, 0.99-1.01).


***


# Spearman correlation

```{r}
regression %>% 
  filter(dev != "all") %$% 
  cor.test(sample_size, dalys, method = "spearman") %>% 
  broom::tidy() %>% 
  sable()
```



# Documentation {.tabset}

## Session Info

```{r session_info, echo=FALSE}
print(sessionInfo(), locale = F)
```


## References

```{r refs, echo=FALSE}
(.packages()) %>% sort %>% lapply(citation) %>% lapply(c) %>% unique
```
